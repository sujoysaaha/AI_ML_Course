{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3561c56",
   "metadata": {},
   "source": [
    "# Machine Learning - ASSIGNMENT 2: CLASSIFICATION\n",
    "\n",
    "## Implement multiple classification models - \n",
    "## Build an interactive Streamlit web application to demonstrate your models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7be6ad",
   "metadata": {},
   "source": [
    "STUDENT INFORMATION (REQUIRED - DO NOT DELETE)\n",
    "\n",
    "BITS ID : [2025ab05083]\n",
    "\n",
    "Name    : [SUJOY SAHA]\n",
    "\n",
    "Email   : [2025ab05083@wilp.bits-pilani.ac.in]\n",
    "\n",
    "Date    : [15-02-2026]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afa82e11",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "ASSIGNMENT OVERVIEW\n",
    "\n",
    "Machine Learning Classification models and Evaluation metrics \n",
    "Implement the following classification models using the dataset chosen from any public repository - \n",
    "Kaggle or UCI. It may be a binary classification problem or a multi-class classification problem. \n",
    "All the 6 ML models have to be implemented on the same dataset. \n",
    "\n",
    "1. Logistic Regression \n",
    "2. Decision Tree Classifier \n",
    "3. K-Nearest Neighbor Classifier \n",
    "4. Naive Bayes Classifier - Gaussian or Multinomial \n",
    "5. Ensemble Model - Random Forest \n",
    "6. Ensemble Model - XGBoost \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be209f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972a1a99",
   "metadata": {},
   "source": [
    "### 1.1 Dataset Selection and Loading\n",
    "\n",
    "TODO: Load your chosen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84616d87-359f-4e07-8429-cd2e690ecfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source_public = \"https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\"\n",
    "# Load CSV\n",
    "data = pd.read_csv(\"breast_cancer_data.csv\")\n",
    "\n",
    "# Remove unwanted columns\n",
    "data = data.drop(columns=[\"id\"], errors=\"ignore\")\n",
    "data = data.loc[:, ~data.columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "# Fix diagnosis\n",
    "data[\"diagnosis\"] = data[\"diagnosis\"].str.upper()\n",
    "data[\"diagnosis\"] = data[\"diagnosis\"].map({\"M\": 0, \"B\": 1})\n",
    "\n",
    "# Define X and y\n",
    "X = data.drop(\"diagnosis\", axis=1)\n",
    "y = data[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cae23a37-d369-4a18-aac3-42faefe31925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()\n",
    "#data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d410ae6",
   "metadata": {},
   "source": [
    "### 1.2 Train-Test Split and Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf2f78fa-03db-418a-ac91-83ebd3673c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1059bd58",
   "metadata": {},
   "source": [
    "### 1.3 Define the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27d41e13-3f23-4ae5-a542-2563240c9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Models\n",
    "# ----------------------------\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\"      : DecisionTreeClassifier(),\n",
    "    \"KNN\"                : KNeighborsClassifier(),\n",
    "    \"Naive Bayes\"        : GaussianNB(),\n",
    "    \"Random Forest\"      : RandomForestClassifier(),\n",
    "    \"XGBoost\"            : XGBClassifier(eval_metric=\"logloss\")\n",
    "}\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709a1426",
   "metadata": {},
   "source": [
    "### 2.1 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0fd6a14-e7d1-4073-b487-67f127c5b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Train & Evaluate\n",
    "# ----------------------------\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    results[name] = {\n",
    "        \"Accuracy\"    : accuracy_score(y_test, y_pred),\n",
    "        \"AUC\"         : roc_auc_score(y_test, y_prob),\n",
    "        \"Precision\"   : precision_score(y_test, y_pred),\n",
    "        \"Recall\"      : recall_score(y_test, y_pred),\n",
    "        \"F1\"          : f1_score(y_test, y_pred),\n",
    "        \"MCC\"         : matthews_corrcoef(y_test, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bbd4ca-0f1a-4e1c-b74e-372db466fc1b",
   "metadata": {},
   "source": [
    "## Save the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f15139e-dd8a-40c2-b6bc-6b4c8be36d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Accuracy       AUC  Precision    Recall        F1  \\\n",
      "Logistic Regression  0.973684  0.997380   0.972222  0.985915  0.979021   \n",
      "Decision Tree        0.947368  0.943990   0.957746  0.957746  0.957746   \n",
      "KNN                  0.947368  0.981985   0.957746  0.957746  0.957746   \n",
      "Naive Bayes          0.964912  0.997380   0.958904  0.985915  0.972222   \n",
      "Random Forest        0.964912  0.995087   0.958904  0.985915  0.972222   \n",
      "XGBoost              0.956140  0.990829   0.958333  0.971831  0.965035   \n",
      "\n",
      "                          MCC  \n",
      "Logistic Regression  0.943898  \n",
      "Decision Tree        0.887979  \n",
      "KNN                  0.887979  \n",
      "Naive Bayes          0.925285  \n",
      "Random Forest        0.925285  \n",
      "XGBoost              0.906379  \n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Save models & scaler\n",
    "# ----------------------------\n",
    "with open(\"model/saved_models.pkl\", \"wb\") as f:\n",
    "    pickle.dump(models, f)\n",
    "\n",
    "with open(\"model/scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(pd.DataFrame(results).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00f5f549-39f0-49fe-833f-4ca513c3dbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nObservation & Analysis:\\n\\nBecause the dataset is small and nearly linearly separable. Complex ensemble models do not gain significant advantage \\nover Logistic Regression in such cases.\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Observation & Analysis:\n",
    "\n",
    "Because the dataset is small and nearly linearly separable. Complex ensemble models do not gain significant advantage \n",
    "over Logistic Regression in such cases.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9070e97-c517-447f-9c8a-4a1d55888a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Logistic Regression', 'Decision Tree', 'KNN', 'Naive Bayes', 'Random Forest', 'XGBoost'])\n"
     ]
    }
   ],
   "source": [
    "with open(\"model/saved_models.pkl\", \"rb\") as f:\n",
    "    loaded_models = pickle.load(f)\n",
    "\n",
    "print(loaded_models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe9f4c-6234-46a5-9194-01e48f9732da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
